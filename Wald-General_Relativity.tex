\documentclass{note}

\usepackage{mathrsfs}
\usepackage{geometry}
\usepackage{xcolor}
\usepackage{fontspec}
\usepackage{titlesec}
\usepackage{fmtcount}


\titleformat{\chapter}[display]
    {\fontspec{Times New Roman}}
    {\NUMBERstring{chapter}}
    {1pt}
    {\hrule\vspace{6pt}\Large\fontspec{Times New Roman}\MakeUppercase}
\renewcommand{\thesection}{\thechapter.\arabic{section}}
\titleformat{\section}[block]
    {\Large\bfseries}
    {\thesection}
    {1em}
    {\fontspec{Times New Roman}\selectfont}


\numberwithin{equation}{chapter}
\makeatletter
\def\tagform@#1{\maketag@@@{[\ignorespaces#1\unskip\@@italiccorr]}}
\makeatother

\newcounter{exercise}[chapter]
\newcommand\Ex{
    \if@noskipsec \leavevmode \fi
    \par
    \refstepcounter{exercise}
    \noindent{\bfseries\arabic{exercise}.}
}

\renewcommand{\theenumi}{\alph{enumi}}

\newcommand{\vat}[2]{\left.#1\right\rvert_{#2}}
\newcommand{\pdv}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\pdvf}[2]{\frac{\partial}{\partial #1}\prn{#2}}


\begin{document}

\chapter{Introduction}

\section*{Problem}

\Page{9}

\Ex \textit{Car and garage paradox.} We set up global inertial coordinates
$t, x, y, z$ for the doorman and $t', x', y', z'$ for the driver. Assume that
the car travels in the $x$ and $x'$ directions in the two systems, that the
garage door is located at $x = y = z = 0$ in the doorman's coordinates and the
back end of the car is located at $x' = y' = z' = 0$ in the driver's
coordinates, and that the back end of the car enters the garage at time
$t = t' = 0$. Also assume that the car and the garage have the same length L.

We note down the Lorentz transform:
\begin{align}
    t' & = (t - vx/c^2)/(1-v^2/c^2)^{1/2}, \label{Lorentz-1} \\
    x' & = (x - vt)/(1 - v^2/c^2)^{1/2}. \label{Lorentz-2}
\end{align}

At $t = 0$, we assume the doorman sees the front end of the car at $x = x_1$.
Because $x'_1 = L$, from \eqref{Lorentz-2} we get $$L = (x_1 - v\cdot 0)/(1 -
    v^2/c^2)^{1/2}$$ or $$x_1 = (1 - v^2/c^2)^{1/2}L < L.$$ So the doorman was
correct that the car fitted into the garage when they slammed the door.

Now assume the driver sees the back wall of the garage at $x' = x'_2$ when the
door is slammed at $t' = 0$. We plug the values $t'_2 = 0, x_2 = L$ into
\eqref{Lorentz-1} and \eqref{Lorentz-2} to get
\begin{align*}
    0    & = (t_2 - vL/c^2)/(1-v^2/c^2)^{1/2}, \\
    x'_2 & = (L - vt_2)/(1 - v^2/c^2)^{1/2},
\end{align*}
from which we solve
\begin{align*}
    t_2  & = vL/c^2,                   \\
    x'_2 & = (1 - v^2/c^2)^{1/2}L < L.
\end{align*}
So the driver is also correct.

If we want to analyze the case that the car decelerates and does not crash into
the back wall, we would have to introduce non-inertial coordinates.

\chapter{Manifolds and Tensor Fields}

\setcounter{section}{2}
\section{Tensors; the Metric Tensor}

\Page{17}

\begin{quotebar}
    Had we chosen a different chart, $\mathtt{\psi}'$, we would have obtained a
    different coordinate basis $\{X'_\nu\}$. We can, of course, express $X_\mu$ in
    terms of the new basis $\{X'_\nu\}$. Using the chain rule of advanced calculus,
    we have
    \begin{equation*}
        X_\mu = \sum_{\nu=1}^n \vat{\pdv{x'^\nu}{x^\mu}}{\psi(p)} X'_\nu,
    \end{equation*}
    where $x'^\nu$ denotes the $\nu$th component of the map $\psi'\circ\psi^{-1}$.
\end{quotebar}

\begin{proof}
    Let $f \in \mathscr{F}$, $X_\mu$ acting on $f$ gives rise to
    \begin{align*}
        X_\mu(f) & = \vat{\pdvf{x^\mu}{f\circ\psi^{-1}}}{\psi(p)}                          \\
                 & = \vat{\pdvf{x^\mu}{f\circ\psi'^{-1}\circ\psi'\circ\psi^{-1}}}{\psi(p)} \\
                 & = \sum_{\nu=1}^n \vat{\pdvf{x'^\nu}{f\circ\psi'^{-1}}}{\psi'(p)}
        \vat{\pdv{\prn{\psi'\circ\psi^{-1}}^\nu}{x^\mu}}{\psi(p)}                          \\
                 & = \sum_{\nu=1}^n \vat{\pdv{x'^\nu}{x^\mu}}{\psi(p)} \qedhere
        X'_\nu(f).
    \end{align*}
\end{proof}

\Page{20}

\begin{quotebar}
    For example, a tensor $T$ of type $(1,1)$ is a multilinear map from $V^* \times
        V \to R$. Hence, if we fix $v \in V$, $T(\cdot,v)$ is an element of $V^{**}$,
    which we identify with an element of $V$. Thus, given a vector in $V$, $T$
    produces another vector in $V$ in a linear fashion. In other words, we can view
    a tensor of type $(1,1)$ as a linear map from $V$ into $V$, and vice versa.
\end{quotebar}

The above quote associates a tensor to a linear map. We want to define the
reverse association and show it is the inverse of the forward association.
Actually, given any linear map $L\colon V \to V$, the map $(v^*, v) \mapsto
    v^*(L(v))$ defines a tensor of type $(1,1)$. Now assume $L$ is the linear map
associated with tensor $T$. For fixed $v \in V$, by the quote $T(\cdot,v)$ as
an element of $V^{**}$ is identified with $L(v)$, meaning for any $v^* \in
    V^*$, $T(v^*,v) = v^*(L(v))$. This shows the reverse association is indeed the
inverse of the forward one.

\setcounter{section}{3}
\section{The Abstract Index Notation}

\Page{25}

\begin{quotebar}
    Since a metric $g$ is a tensor of type $(0,2)$, it is denoted $g_{ab}$. If we
    apply the metric to a vector, $v^a$, we get the dual vector $g_{ab}v^b$.
\end{quotebar}

To make sense of $g_{ab}v^b$, we view $v$ as an element of $V_p^{**}$, thus a
tensor of type $(1,0)$ and $g_{ab}v^b$ as a contraction of the outer product of
$g$ and $v$. We want to show that the dual vector obtained by applying $g$ to
$v$, i.e., $u \mapsto g(u,v)$, is just $g_{ab}v^b$.
\begin{proof}
    Let $\set{w_\sigma}$ be a basis of $V_p$ and $\set{w^{\sigma^*}}$ its dual
    baiss. For any $u \in V_p$, $g_{ab}v^b$ evaluated at $u$ by definition is
    \begin{equation}
        g_{ab}v^b(u) = \sum_{\sigma=1}^n g(u, w_\sigma)v\prn{w^{\sigma^*}} =
        \sum_{\sigma=1}^n g(u, w_\sigma)w^{\sigma^*}(v) = g\prn{u, \sum_{\sigma=1}^n
            w^{\sigma^*}(v) w_\sigma} = g(u,v). \label{eq:contraction-technique} \qedhere
    \end{equation}
\end{proof}

\begin{quotebar}
    The inverse of $g_{ab}$ is a tensor of type $(2,0)$ and could be denoted as
    $\prn{g^{-1}}^{ab}$. It is convenient, however, to drop the inverse sign and
    denote it simply as $g^{ab}$... by definition, $g^{ab}g_{bc} = {\delta^a}_c$,
    where ${\delta^a}_c$ (viewed as a map from $V_p$ into $V_p$) is the identity
    map.
\end{quotebar}

Let $L\colon V\to V^*$ denote the linear map induced by $g$, i.e., $g(u, v) =
    L(v)(u)$ for any $u, v \in V_p$. By definition, for any $u^*, v^* \in V_p^*$,
$g^{-1}(u^*, v^*) = L^{-1}(v^*)(u^*) = u^*\prn{L^{-1}(v^*)}$. Let
$\set{w_\sigma}$ be a basis of $V_p$ and $\set{w^{\sigma^*}}$ its dual basis.
Then for any $u^* \in V_p^*$, $v \in V_p$, we have
\begin{align}
    g^{ab}g_{bc}(u^*, v)
     & = \sum_{\sigma=1}^n g^{-1}\prn{u^*, w^{\sigma^*}} g\prn{w_\sigma, v} \notag     \\
     & = \sum_{\sigma=1}^n u^*\prn{L^{-1}\prn{w^{\sigma^*}}} L(v)\prn{w_\sigma} \notag \\
     & = \sum_{\sigma=1}^n u^*\prn{L(v)\prn{w_\sigma}L^{-1}\prn{w^{\sigma^*}}} \notag  \\
     & = \sum_{\sigma=1}^n u^*\prn{L^{-1}\prn{L(v)\prn{w_\sigma}w^{\sigma^*}}} \notag  \\
     & = u^*\prn{L^{-1}\prn{\sum_{\sigma=1}^n L(v)\prn{w_\sigma}w^{\sigma^*}}}.
    \label{eq:prove-metric-inverse}
\end{align}
Using the same technique used in \eqref{eq:contraction-technique}, one has for
all $x \in V_p$,
\begin{equation*}
    \sum_{\sigma=1}^n L(v)\prn{w_\sigma}w^{\sigma^*}(x)
    = \sum_{\sigma=1}^n L(v)\prn{w^{\sigma^*}(x) w_\sigma}
    = L(v)\prn{\sum_{\sigma=1}^n w^{\sigma^*}(x) w_\sigma}
    = L(v)(x),
\end{equation*}
thus the equality between the following two dual vectors,
\begin{equation*}
    \sum_{\sigma=1}^n L(v)\prn{w_\sigma}w^{\sigma^*} = L(v).
\end{equation*}
Plugging this into \eqref{eq:prove-metric-inverse}, we get
\begin{equation*}
    g^{ab}g_{bc}(u^*, v) = u^*\prn{L^{-1}(L(v))} = u^*(v) =
    {\delta^a}_c\prn{u^*,v}.
\end{equation*}

\end{document}
